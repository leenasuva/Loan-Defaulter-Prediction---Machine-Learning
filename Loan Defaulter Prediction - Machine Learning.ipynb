{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b88f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import plotly.express as px\n",
    "import imblearn\n",
    "import seaborn as sns\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40303f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "df_orig = pd.read_csv('Training Data.csv')\n",
    "\n",
    "# Presenting data in the dataframe.\n",
    "df_orig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bef640",
   "metadata": {},
   "source": [
    "**1. Show overall descriptive statistics of your dataset; number of data points, number of descriptive features, type of features, your target feature, and its type. (10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of records present currently in the dataframe. Here 252000 indicates the number of rows \n",
    "# and 13 indicates the number of columns present.\n",
    "df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the columns in the dataframe along with respective data type.\n",
    "df_orig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6164220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardising the Feature names in the dataframe.\n",
    "df_orig.rename(columns={'CITY':'City','STATE':'State','CURRENT_JOB_YRS':'Current_Job_Years',\n",
    "                   'CURRENT_HOUSE_YRS':'Current_House_Years'},inplace=True)\n",
    "(df_orig.columns).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94cef5a",
   "metadata": {},
   "source": [
    "**The following dataframe is enlightening us more about the dataset. The types of features are described with respect to the datatype as well as the category to which each feature is belonging to.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data description of all features present in the file.\n",
    "data_desc = pd.read_csv('Data_Dictionary.csv')\n",
    "data_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude target label from given features in analysis\n",
    "df = df_orig.iloc[:,:-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8bf9c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Segragating numerical features.\n",
    "numerical_vars = data_desc[(data_desc['Data_Type']=='int') & (data_desc['Column_Name'] != 'Risk_Flag')]['Column_Name']\n",
    "numerical_vars.reset_index(drop=True, inplace=True)\n",
    "numerical_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segragating string variables, all of which are categorical\n",
    "string_vars = data_desc[data_desc['Data_Type']=='string']['Column_Name']\n",
    "string_vars.reset_index(drop=True, inplace=True)\n",
    "string_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a8441",
   "metadata": {},
   "source": [
    "**The statistical information of the numerical features in our dataset is as follows:-**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9da118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Information about the numeric data\n",
    "desc_numeric = pd.DataFrame()\n",
    "\n",
    "for var in numerical_vars:\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[\"Feature\"] = [var]\n",
    "    temp_df[\"Total Count\"] = len(df[var])\n",
    "    temp_df[\"Null Value Count\"] = [df[var].isnull().sum()]\n",
    "    temp_df[\"Cardinality\"] = [df[var].nunique()]\n",
    "    temp_df[\"Maximum Value\"] = [df[var].max()]\n",
    "    temp_df[\"Mininum Value\"] = [df[var].min()]\n",
    "    temp_df[\"Q1\"] = [df[var].quantile(0.25)]\n",
    "    temp_df[\"Mean Value\"] = [df[var].mean()]\n",
    "    temp_df[\"Q3\"] = [df[var].quantile(0.75)]\n",
    "    temp_df[\"Std. Dev\"] = [df[var].std()]     \n",
    "    desc_numeric = pd.concat([desc_numeric,temp_df])\n",
    "    \n",
    "desc_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a828a302",
   "metadata": {},
   "source": [
    "**The statistical information for all the features which are categorical and of string type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e99b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Information about the string data\n",
    "desc_string = pd.DataFrame()\n",
    "\n",
    "for var in string_vars:\n",
    "    temp_df = pd.DataFrame()\n",
    "    temp_df[\"Feature\"] = [var]\n",
    "    temp_df[\"Total Count\"] = len(df[var])\n",
    "    temp_df[\"Null Value Count\"] = [df[var].isnull().sum()]\n",
    "    temp_df[\"Cardinality\"] = [df[var].nunique()]\n",
    "    temp_df[\"Mode Value\"] = [df[var].mode()[0]]\n",
    "    temp_df[\"Mode Frequency\"] = [(df[var]==temp_df[\"Mode Value\"][0]).sum()]\n",
    "    temp_df[\"Mode Ratio\"] = [(df[var]==temp_df[\"Mode Value\"][0]).sum()]/temp_df[\"Total Count\"]    \n",
    "    desc_string = pd.concat([desc_string,temp_df])\n",
    "    \n",
    "desc_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c05232",
   "metadata": {},
   "source": [
    "**2. Explore your features further in their distributions and plot their box plots. Show outliers for each feature. Do you think any of the outliers may impact your analysis? Why? Provide supporting visualizations with their analysis. (20 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f7567",
   "metadata": {},
   "source": [
    "#### Plotting Histograms of all Numeric features along with their probability density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27d48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To study Data Distribution of Numeric columns. Excluding the 'Id' column as it has unique values for each entry.\n",
    "\n",
    "numerical_vars = numerical_vars[1:]\n",
    "for num in numerical_vars:\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(7, 7))\n",
    "    sns.histplot(data=df[numerical_vars], x=num,kde=True).set_title(\"Histogram for {}\".format(num),fontsize=14,fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927296e",
   "metadata": {},
   "source": [
    "### Plotting Bar Graphs for portraying the distribution of some of the Categorical Variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8747a91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the City, Profession and State columns in depicting the frequency distribution of String Variables.\n",
    "string_vars = string_vars[0:3]\n",
    "\n",
    "for val in string_vars:\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    df[val].value_counts().plot(kind='bar',ylabel=\"Frequency\",color='#69b3a2',rot=0,fontsize=12).set_title(\"Bar Plot for {} \".format(val),fontsize=14,fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7b64ee",
   "metadata": {},
   "source": [
    "We have conmputed the boxplots for all the numeric features which are present in our dataset. As evident from the below Boxplots there aren't any outliers present in our dataset. None of the input datapoints which will be passed on the our model eventually are more than 1.5(IQR) above the upper quartile or more than 1.5(IQR) below the lower quartile. We do not possessany data point which is conspicuously diverse from the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot created for numeric features using seaborn\n",
    "for num in numerical_vars:\n",
    "    sns.set(style=\"darkgrid\")\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(7, 7))\n",
    "    sns.boxplot(data=df[num],palette='deep').set_title(\"Boxplot for {} \".format(num),fontsize=14,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d684ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualising the data set with all the numerical variables\n",
    "sc_x = MinMaxScaler()\n",
    "pd.DataFrame(sc_x.fit_transform(df[numerical_vars]),columns=df[numerical_vars].columns).plot(kind='box',figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5421c47",
   "metadata": {},
   "source": [
    "**4. What data pre-processing do you apply? E.g., encoding features, missing values, scaling, etc. Explain each process and why you use it. (10 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6d90b",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa43b29",
   "metadata": {},
   "source": [
    "**In order to remove inconsistencies in the categorical(texual) features, we have created a function which will eliminate numbers if not deemed necessary for that particular feature. It will also clean the additional parentheses, punctuation and any special characters. We have then added the refined data back to our dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cdbe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_desc[data_desc['Data_Type']=='string']['Column_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804841c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_str_df = pd.DataFrame()\n",
    "temp_unclean_cols = data_desc[data_desc['Data_Type']=='string']['Column_Name']\n",
    "temp_str_df = df[temp_unclean_cols[3:]]\n",
    "temp_str_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[temp_unclean_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b678f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.encode('ascii', errors='ignore').decode('utf8')\n",
    "    text = re.sub(r\"[()\\[\\]]\" , \"\" , text)\n",
    "    text = re.sub(r\"[0-9]\" , \"\" , text)   \n",
    "    text = re.sub(r\"[_]\" , \" \" , text)\n",
    "    return (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172ed6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_cols = temp_unclean_cols[3:]\n",
    "for i in temp_cols:\n",
    "    temp_str_df[i] = temp_str_df[i].apply(clean_text)\n",
    "\n",
    "temp_str_df['Id'] = df_orig['Id']\n",
    "temp_str_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_begin = df.iloc[:,0:7]\n",
    "df_end = df.iloc[:,[0,-2,-1]]\n",
    "\n",
    "df_refined = df_begin.merge(temp_str_df,on='Id',how='inner')\n",
    "df_refined = df_refined.merge(df_end,on='Id',how='inner')\n",
    "df_refined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781eea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.treemap(df_refined, values = \"Income\", path = [\"Current_Job_Years\", \"Profession\"], hover_name = \"Profession\", color = \"Experience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecbc471",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.sunburst(df_refined, values = \"Current_House_Years\", color = \"Age\", \n",
    "            path = [\"House_Ownership\", \"Current_House_Years\", \"Age\"], color_continuous_scale = \"tealgrn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b89573",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(df_refined, x = \"Married/Single\", hover_name = \"Age\", color = \"Car_Ownership\",nbins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c3ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_json = r'India_Geodata.json'\n",
    "\n",
    "fig = px.choropleth(\n",
    "    df_refined,\n",
    "    geojson = india_json,\n",
    "    featureidkey = 'properties.ST_NM',\n",
    "    locations = 'State',\n",
    "    color = 'Income',\n",
    "    color_continuous_scale = 'Reds'\n",
    ")\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d64158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str = df_refined[['Married/Single', 'House_Ownership', 'Car_Ownership','State']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c071b02",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "** We have performed encoding on categorical variables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "lencoder = {}\n",
    "for i in df_str.columns:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    df_str[i] = label_encoder.fit_transform(df_str[i])\n",
    "    lencoder[i] = label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_str.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c55c9c4",
   "metadata": {},
   "source": [
    "### One-Hot Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9e0bf",
   "metadata": {},
   "source": [
    "**As we are aware that Scikit learn models work only on numeric data, we have encoded the necessary categorical features to numeric format using 'One-Hot' Encoding technique. This technique will convert our textual data to an array of 0s and 1s.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oheencoder = {}\n",
    "col_names = []\n",
    "df_ohe = pd.DataFrame()\n",
    "dfs=[]\n",
    "for i in df_str.columns:\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    col_names = [str(i)+'_'+str(x) for x in lencoder[i].classes_]\n",
    "    df_temp = pd.DataFrame(enc.fit_transform(df_str.loc[:,[i]]).toarray(),columns=col_names)\n",
    "    oheencoder[i] = enc\n",
    "    dfs.append(df_temp)\n",
    "df_ohe = pd.concat(dfs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c117021c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ohe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10476/1012268583.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_ohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_ohe' is not defined"
     ]
    }
   ],
   "source": [
    "df_ohe.head(5).iloc[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a02bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will combine the numberical and one hot encoded vectors\n",
    "df_processed = pd.concat([df_refined[numerical_vars], df_ohe], axis = 1)\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8cbecf",
   "metadata": {},
   "source": [
    "**5. Analyze the balance or distribution of your target variable. Do you think any of these will present a problem and why? Provide supporting visualizations with their analysis. (10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are checking the distribution of our target variable\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('Risk_Flag',fontsize=16)\n",
    "plt.ylabel('Count',fontsize=16)\n",
    "ax=sns.countplot(x=df_orig['Risk_Flag'], data=df_orig)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.38, p.get_height()), ha='center', va='top', color='white', size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674e19b",
   "metadata": {},
   "source": [
    "**The above countplot exhibits the distribution of our target variable 'Risk_Flag'. Unfortunately we are posed with imbalanced data for the target variable. This may influence the learning of our model/s and may provide us with biased results. We will explore that shortly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358cf8d",
   "metadata": {},
   "source": [
    "**6. What kind of ML approaches and algorithms do you take and why? E.g., supervised,\n",
    "regression, classification, binary, multi-class, split rate of data, logistic regression, SVM,\n",
    "decision trees etc. Provide supporting visualizations with their analysis. (10 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_processed.values\n",
    "y = df_orig.Risk_Flag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425b60f",
   "metadata": {},
   "source": [
    "## Scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ecb5f",
   "metadata": {},
   "source": [
    "**The scaling technique that we have used which will scale our near final dataset is Scikit learn's StandardScaler. It standardises features by calculating the mean and scaling to unit varaince, so that if the data possesses high variance then the scaler would scale down the data to fit it within the range of 0 to 1. Performing scaling refrains the features with high variance from biasing the learning of the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946e5c8e",
   "metadata": {},
   "source": [
    "### Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "709a2421",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10476/1406852878.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msc_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4d7d0",
   "metadata": {},
   "source": [
    "### Correlation Matrix - Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ce077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap showing the correlation between the features\n",
    "\n",
    "plt.figure(figsize = (15, 8))\n",
    "hm = sns.heatmap(df_refined.corr(), vmin = -1, vmax = 1, annot = True, cmap = 'RdBu')\n",
    "hm.set_title('Feature Correlation', fontdict = {'fontsize' : 18}, pad = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ce96d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3302859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression(random_state = 0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff477463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def get_results(classifier):\n",
    "    y_pred=classifier.predict(x_test)\n",
    "    pred_prob1 = classifier.predict_proba(x_test)\n",
    "    fpr, tpr, thresh = roc_curve(y_test, pred_prob1[:,1], pos_label=1)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    auc = round(roc_auc_score(y_test, pred_prob1[:,1]),2)\n",
    "    print('AUC Score is - ',auc)\n",
    "    f1 = round(f1_score(y_test, y_pred, average='macro'),2) \n",
    "    return (fpr, tpr, thresh, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66e3026",
   "metadata": {},
   "source": [
    "**Performance Metrics for Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75380f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr1, tpr1, thresh1, f1 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352dae06",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80439a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d55649",
   "metadata": {},
   "source": [
    "**Performance metrics using Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431bbcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr2, tpr2, thresh2, f2 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b429ecbe",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state = 0)\n",
    "classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d80e3a",
   "metadata": {},
   "source": [
    "**Performance metrics using Random Forest Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06863671",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr3, tpr3, thresh3, f3 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ea09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.1)\n",
    "classifier = classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eaa5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr4, tpr4, thresh4, f4 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "classifier = xgb.XGBClassifier(learning_rate = 0.1)\n",
    "classifier = classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18a181",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr5, tpr5, thresh5, f5 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f6e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55065b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc_x = MinMaxScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb33207",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "classifier.add(tf.keras.layers.Dense(units = 21, activation = 'relu', input_shape = (41,)))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "classifier.add(tf.keras.layers.Dense(units = 21, activation = 'relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "classifier.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "classifier.fit(x_train, y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e115327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results1(classifier):\n",
    "    pred_prob1=classifier.predict(x_test).flatten()\n",
    "    y_pred = (pred_prob1 > 0.5)\n",
    "    fpr, tpr, thresh = roc_curve(y_test, pred_prob1, pos_label=1)\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    auc = round(roc_auc_score(y_test, pred_prob1),2)\n",
    "    print('AUC Score is - ',auc)\n",
    "    f1 = round(f1_score(y_test, y_pred, average='macro'),2) \n",
    "    return (fpr, tpr, thresh, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b931fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr6, tpr6, thresh6, f6 = get_results1(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f714d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_per():\n",
    "    models_names = ['Logistic Regression','Decision Tree','Random Forest','Gradient Boosting','XGBoost','ANN']\n",
    "    f1_scores = np.array([f1,f2,f3,f4,f5,f6])\n",
    "    indices = np.argsort(f1_scores)\n",
    "\n",
    "    num_models = 6 \n",
    "\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.title('Model Comparision')\n",
    "\n",
    "    # only plot the customized number of features\n",
    "    plt.barh(range(num_models), f1_scores[indices[-num_models:]], color='b', align='center')\n",
    "    plt.yticks(range(num_models), [models_names[i] for i in indices[-num_models:]])\n",
    "    plt.xlabel('F1-Score')\n",
    "    plt.xlim((0,1))\n",
    "    k=0\n",
    "    for j in [f1_scores[i] for i in indices[-num_models:]]:\n",
    "        plt.annotate(j,xy=(0.05,k))\n",
    "        k+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8dda9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_per()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540da0e",
   "metadata": {},
   "source": [
    "### Balancing the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf50789",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_processed.values\n",
    "y = df_orig.Risk_Flag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.3)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = pipeline.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('Risk_Flag',fontsize=16)\n",
    "plt.ylabel('Count',fontsize=16)\n",
    "ax=sns.countplot(x=y, data=df_orig)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.38, p.get_height()), ha='center', va='top', color='white', size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7490f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression(random_state = 0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57432bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr1, tpr1, thresh1,f1 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5829f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr2, tpr2, thresh2, f2 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa1444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state = 0)\n",
    "classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr3, tpr3, thresh3, f3 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier(learning_rate=0.1)\n",
    "classifier = classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f75502",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr4, tpr4, thresh4, f4 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0644b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "classifier = xgb.XGBClassifier(learning_rate = 0.1)\n",
    "classifier = classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr5, tpr5, thresh5, f5 = get_results(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29489ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc_x = MinMaxScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa724de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.models.Sequential()\n",
    "classifier.add(tf.keras.layers.Dense(units = 21, activation = 'relu', input_shape = (41,)))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "classifier.add(tf.keras.layers.Dense(units = 21, activation = 'relu'))\n",
    "classifier.add(tf.keras.layers.Dropout(0.2))\n",
    "classifier.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "classifier.fit(x_train, y_train, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b258eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr6, tpr6, thresh6, f6 = get_results1(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_per()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6ee320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc():\n",
    "    random_probs = [0 for i in range(len(y_test))]\n",
    "    p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)\n",
    "\n",
    "    # plot roc curves\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(fpr1, tpr1, linestyle='--',color='green', label='F1-'+str(f1)+', Logistic Regression')\n",
    "    plt.plot(fpr2, tpr2, linestyle='--',color='teal', label='F1-'+str(f2)+', Decision Tree')\n",
    "    plt.plot(fpr3, tpr3, linestyle='--',color='orange', label='F1-'+str(f3)+', Random Forest')\n",
    "    plt.plot(fpr4, tpr4, linestyle='--',color='blue', label='F1-'+str(f4)+', Gradient Boosting')\n",
    "    plt.plot(fpr5, tpr5, linestyle='--',color='red', label='F1-'+str(f5)+', XGBoost')\n",
    "    plt.plot(fpr6, tpr6, linestyle='--',color='yellow', label='F1-'+str(f6)+', ANN')\n",
    "\n",
    "    plt.plot(p_fpr, p_tpr, linestyle='--', color='red')\n",
    "    # title\n",
    "    plt.title('ROC curve')\n",
    "    # x label\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    # y label\n",
    "    plt.ylabel('True Positive rate')\n",
    "\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_features(classifier,top=10):\n",
    "    features = df_processed.columns\n",
    "    importances = classifier.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "\n",
    "    # customized number \n",
    "    num_features = top \n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.title('Feature Importances')\n",
    "\n",
    "    # only plot the customized number of features\n",
    "    plt.barh(range(num_features), importances[indices[-num_features:]], color='b', align='center')\n",
    "    plt.yticks(range(num_features), [features[i] for i in indices[-num_features:]])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e10351",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb266fec",
   "metadata": {},
   "source": [
    "#### Here we can see that numerical features have more importance and all other features are very insigificant to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9423f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.concat([df_refined[numerical_vars]], axis = 1)\n",
    "df_processed\n",
    "x = df_processed.values\n",
    "y = df_orig.Risk_Flag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b59ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.3)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91952ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = pipeline.fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc716c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b92631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state = 0)\n",
    "classifier.fit(x_train,y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr7, tpr7, thresh7, f7 = get_results1(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_per():\n",
    "    models_names = ['Logistic Regression','Decision Tree','Random Forest','Gradient Boosting','XGBoost','ANN','Random Forest(Numaric)']\n",
    "    f1_scores = np.array([f1,f2,f3,f4,f5,f6,f7])\n",
    "    indices = np.argsort(f1_scores)\n",
    "\n",
    "    num_models = 7 \n",
    "\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.title('Model Comparision')\n",
    "\n",
    "    # only plot the customized number of features\n",
    "    plt.barh(range(num_models), f1_scores[indices[-num_models:]], color='b', align='center')\n",
    "    plt.yticks(range(num_models), [models_names[i] for i in indices[-num_models:]])\n",
    "    plt.xlabel('F1-Score')\n",
    "    plt.xlim((0,1))\n",
    "    k=0\n",
    "    for j in [f1_scores[i] for i in indices[-num_models:]]:\n",
    "        plt.annotate(j,xy=(0.05,k))\n",
    "        k+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dfd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_per()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
